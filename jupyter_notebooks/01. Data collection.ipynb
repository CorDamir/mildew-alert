{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **DATA COLLECTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and organize into train, validate and test sets using folders\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file with authentication token\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Organized dataset:\n",
        "    - inputs/dataset/cherry-leaves/train folder\n",
        "    - inputs/dataset/cherry-leaves/validation folder\n",
        "    - inputs/dataset/cherry-leaves/test folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"./..\")  # change to parent directory\n",
        "working_dir = os.getcwd()\n",
        "working_dir  # check output for correct directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Fetch dataset from kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set kaggle configuration and download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = working_dir\n",
        "\n",
        "dataset_url = \"codeinstitute/cherry-leaves\"\n",
        "dl_destination = \"inputs/dataset/raw\"\n",
        "\n",
        "! kaggle datasets download -d {dataset_url} -p {dl_destination}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unzip dataset file and remove zip file and it's folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zip_path = dl_destination + \"/cherry-leaves.zip\"\n",
        "destination_folder = working_dir + \"/inputs/dataset/\"\n",
        "\n",
        "with ZipFile(zip_path, \"r\") as zip_file:\n",
        "    zip_file.extractall(destination_folder)\n",
        "\n",
        "os.remove(zip_path)\n",
        "os.rmdir(dl_destination)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Organize data into train, validation and test folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All files in the dataset are in .jpg format and contain images of interest, no need for additional preparation.\n",
        "\n",
        "Make a function to randomize and separate dataset into train, validation and test sets with given ratios.\n",
        "Also, make a function to list number of files per folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random, shutil\n",
        "\n",
        "\n",
        "def train_validation_test_split(data_dir, train_ratio, validation_ratio, test_ratio):\n",
        "    \n",
        "    if train_ratio + validation_ratio + test_ratio != 1.0:\n",
        "        print(\"Ratios must add to exactly 1.0\")\n",
        "        return\n",
        "    \n",
        "    categories = os.listdir(data_dir)\n",
        "\n",
        "    if \"test\" in categories:  # prevent creation of sub-divisions on multiple function calls\n",
        "        print(\"Dataset already organized\")\n",
        "        return\n",
        "\n",
        "    for category in categories:\n",
        "        all_files = os.listdir(data_dir + \"/\" + category)\n",
        "        random.shuffle(all_files)\n",
        "\n",
        "        number_of_files = len(all_files)\n",
        "        train_files_number = int(number_of_files * train_ratio)\n",
        "        validation_files_number = int(number_of_files * validation_ratio) + train_files_number\n",
        "\n",
        "        set_names = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "        for name in set_names:\n",
        "            os.makedirs(data_dir + \"/\" + name + \"/\" + category)\n",
        "\n",
        "        for i in range(0, number_of_files):\n",
        "            if i < train_files_number:\n",
        "                set = 0\n",
        "                \n",
        "            elif i < validation_files_number:\n",
        "                set = 1\n",
        "\n",
        "            else:\n",
        "                set = 2\n",
        "\n",
        "            shutil.move(\n",
        "                    data_dir + \"/\" + category + \"/\" + all_files[i],\n",
        "                    data_dir + \"/\" + set_names[set] + \"/\" + category + \"/\" + all_files[i]\n",
        "                    )\n",
        "    \n",
        "        os.rmdir(data_dir + \"/\" + category)\n",
        "\n",
        "\n",
        "def show_number_of_files(data_dir):\n",
        "    for folder in os.listdir(data_dir):\n",
        "        current_dir = data_dir + \"/\" + folder\n",
        "        \n",
        "        for dir in os.listdir(current_dir):\n",
        "            print_dir = current_dir + \"/\" + dir\n",
        "            nr = len(os.listdir(print_dir))\n",
        "            print(f\"{nr} files in {print_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split dataset: 70% train, 10% validate, 20% test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_validation_test_split(\n",
        "    destination_folder + \"/cherry-leaves\",\n",
        "    0.7,\n",
        "    0.1,\n",
        "    0.2\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect number of files per set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_number_of_files(destination_folder + \"/cherry-leaves\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data is now organized and ready for next steps"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
